{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Recipe Co-occurrence Network Analysis\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project focuses on analyzing culinary data to construct and explore a network of recipe similarities. Recipes are connected based on the number of ingredients they share, allowing for a quantitative understanding of ingredient combinations and relationships between different dishes.\n",
    "\n",
    "The core idea is to transform raw recipe-ingredient data into a network graph, enabling the application of network science techniques to uncover hidden structures and patterns in culinary systems.\n",
    "\n",
    "---\n",
    "\n",
    "## 0. Necessary Imports\n",
    "\n",
    "This block includes all the essential Python libraries that will be used in the functions and the main script. It's good practice to place them at the beginning of your notebook to ensure all dependencies are loaded before code execution."
   ],
   "id": "1d5808908fe292ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:28:13.983490Z",
     "start_time": "2025-05-22T18:28:13.971587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.sparse import csr_matrix, triu, coo_matrix\n",
    "import networkx as nx\n",
    "\n",
    "file_path = './culinaryDB/04_Recipe-Ingredients_Aliases.csv'\n",
    "G = nx.Graph()"
   ],
   "id": "6906ac0e7e9d687f",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 1. `sample_recipes_df` Function\n",
    "\n",
    "This function is designed for **recipe data sampling**. It's not always necessary or efficient to work with the entire dataset, especially if it's very large. This function allows you to select a specific percentage of unique recipes from your original dataset.\n",
    "\n",
    "### What it Does:\n",
    "* Takes the complete DataFrame and the desired percentage of recipes to sample.\n",
    "* Identifies all unique recipes in the DataFrame.\n",
    "* Randomly shuffles the list of unique recipes.\n",
    "* Selects the specified percentage of these shuffled recipes.\n",
    "* Filters the original DataFrame to include only the rows related to the sampled recipes. This reduces the size of the dataset we will work with, making subsequent calculations faster.\n",
    "* Prints information about the number of original and sampled recipes to track the effect of sampling.\n"
   ],
   "id": "502564923cf2b79d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:28:14.019814Z",
     "start_time": "2025-05-22T18:28:14.015372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample_recipes_df(df, percentage):\n",
    "    print(f\"\\nApplying sampling: Keeping {percentage*100:.0f}% of unique recipes...\")\n",
    "    unique_recipes = df['Recipe ID'].unique()\n",
    "    num_total_recipes = len(unique_recipes)\n",
    "    np.random.shuffle(unique_recipes)\n",
    "    sample_size = int(num_total_recipes * percentage)\n",
    "    sampled_recipe_ids = unique_recipes[:sample_size]\n",
    "    df_sampled = df[df['Recipe ID'].isin(sampled_recipe_ids)].copy()\n",
    "    print(f\"Original unique recipes: {num_total_recipes}\")\n",
    "    print(f\"Sampled unique recipes: {len(sampled_recipe_ids)}\")\n",
    "    print(f\"DataFrame filtered to {len(df_sampled)} rows for sampled recipes.\")\n",
    "    return df_sampled"
   ],
   "id": "6a38255d71adedf2",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 2. `build_cooccurrence_matrix` Function\n",
    "\n",
    "This is the core function for creating the **co-occurrence matrix**, which is the heart of the analysis. This matrix quantifies how many times each pair of recipes shares the same ingredients. It is optimized to work with large datasets using sparse matrices.\n",
    "\n",
    "### What it Does:\n",
    "* **Data Loading:** Reads the specified CSV file, loading only the 'Recipe ID' and 'Entity ID' columns, which are essential for matrix construction.\n",
    "* **Sampling (Optional):** If a `sample_percentage` less than 1.0 is specified, it calls the `sample_recipes_df` function to reduce the dataset.\n",
    "* **De-duplication:** This is a **crucial** recently added step. It removes duplicate rows based on the combination of 'Recipe ID' and 'Entity ID'. This ensures that if a recipe lists the same ingredient multiple times (as in your basil example), it is counted only once for that recipe. This prevents an artificial inflation of co-occurrence weights.\n",
    "* **ID Mapping:** Converts textual/numerical recipe and ingredient IDs into sequential numerical indices (0, 1, 2, ...) required for matrix operations. It also creates a mapping to retrieve original IDs later.\n",
    "* **Bipartite Matrix:** Constructs a sparse matrix (Recipes x Ingredients) where each cell (i, j) is 1 if recipe `i` contains ingredient `j`. Thanks to de-duplication, each cell will contain at most 1.\n",
    "* **Co-occurrence Matrix Calculation:** Calculates the co-occurrence matrix by multiplying the bipartite matrix by its transpose (`B @ B.T`). The value `C[i,j]` in this matrix represents the number of common ingredients between recipe `i` and recipe `j`.\n",
    "* **Diagonal Cleaning:** Sets the elements on the diagonal to zero (`setdiag(0)`). This is because a recipe co-occurs with itself for all its ingredients, and this value is not significant for similarity analysis.\n",
    "* **Explicit Zero Elimination:** A technical step (`eliminate_zeros()`) to remove any \"explicit zeros\" that might have been stored in the sparse matrix. This is important for maintaining data structure consistency and preventing potential `IndexError`s.\n",
    "* **Thresholding (Optional):** If a `threshold_weight` is specified (> 0), it filters the matrix to keep only connections (co-occurrences) whose weight is strictly greater than this threshold. This helps to remove weak and insignificant connections. Internally, it temporarily converts to COO format for efficient filtering and then reconstructs the matrix.\n",
    "* **Upper Triangle Extraction:** Extracts only the upper part of the matrix (`triu(..., k=1)`). Since the co-occurrence matrix is symmetric and we are building an undirected graph, we only need the upper half to represent all unique connections, saving memory and processing time.\n",
    "* **Return Values:** Returns the final co-occurrence matrix (filtered and upper triangular), the recipe ID-to-index map, and the NumPy array of unique (sampled) recipe IDs.\n"
   ],
   "id": "ca5eb1e3603d6100"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:28:14.030091Z",
     "start_time": "2025-05-22T18:28:14.021395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_cooccurrence_matrix(file_path, sample_percentage=1.0, threshold_weight=0, drop_duplicate_ingredients_per_recipe=True):\n",
    "    \"\"\"\n",
    "    Builds a sparse co-occurrence matrix for recipes based on shared ingredients.\n",
    "    Includes optional sampling, de-duplication and weight thresholding.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Loading data from {file_path}...\")\n",
    "    df = pd.read_csv(file_path, usecols=['Recipe ID', 'Entity ID'])\n",
    "\n",
    "    if sample_percentage < 1.0:\n",
    "        df = sample_recipes_df(df, sample_percentage)\n",
    "\n",
    "    if drop_duplicate_ingredients_per_recipe:\n",
    "        initial_rows = len(df)\n",
    "        df.drop_duplicates(subset=['Recipe ID', 'Entity ID'], inplace=True)\n",
    "        rows_after_dedup = len(df)\n",
    "        if initial_rows > rows_after_dedup:\n",
    "            print(f\"Removed {initial_rows - rows_after_dedup} duplicate (Recipe ID, Entity ID) pairs.\")\n",
    "        else:\n",
    "            print(\"No duplicate (Recipe ID, Entity ID) pairs found.\")\n",
    "    else:\n",
    "        print(\"Skipping deduplication of ingredients per recipe as requested.\")\n",
    "\n",
    "\n",
    "    print(\"Mapping recipe and ingredient IDs to indices...\")\n",
    "    unique_recipe_ids = df['Recipe ID'].unique()\n",
    "    recipe_to_index = {recipe_id: i for i, recipe_id in enumerate(unique_recipe_ids)}\n",
    "    num_recipes = len(unique_recipe_ids)\n",
    "\n",
    "    unique_ingredient_ids = df['Entity ID'].unique()\n",
    "    ingredient_to_index = {ingredient_id: i for i, ingredient_id in enumerate(unique_ingredient_ids)}\n",
    "    num_ingredients = len(unique_ingredient_ids)\n",
    "\n",
    "    print(f\"Found {num_recipes} unique recipes and {num_ingredients} unique ingredients.\")\n",
    "\n",
    "    df['recipe_idx'] = df['Recipe ID'].map(recipe_to_index)\n",
    "    df['ingredient_idx'] = df['Entity ID'].map(ingredient_to_index)\n",
    "\n",
    "    print(\"Creating the sparse bipartite matrix (Recipes x Ingredients)...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    recipe_ingredient_matrix = csr_matrix(\n",
    "        (np.ones(len(df), dtype=int), (df['recipe_idx'], df['ingredient_idx'])),\n",
    "        shape=(num_recipes, num_ingredients)\n",
    "    )\n",
    "\n",
    "    print(f\"Sparse bipartite matrix created in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "    print(\"Calculating the co-occurrence matrix via matrix multiplication (B @ B.T)...\")\n",
    "    start_time = time.time()\n",
    "    cooccurrence_matrix = recipe_ingredient_matrix @ recipe_ingredient_matrix.T\n",
    "    print(f\"Co-occurrence matrix calculated in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "    cooccurrence_matrix.setdiag(0)\n",
    "    cooccurrence_matrix.eliminate_zeros() \n",
    "\n",
    "    if threshold_weight > 0:\n",
    "        print(f\"Applying a weight threshold of > {threshold_weight} to the co-occurrence matrix...\")\n",
    "        \n",
    "        coo_matrix_temp = cooccurrence_matrix.tocoo()\n",
    "        \n",
    "        rows = coo_matrix_temp.row\n",
    "        cols = coo_matrix_temp.col\n",
    "        data = coo_matrix_temp.data\n",
    "        \n",
    "        mask = data > threshold_weight\n",
    "        \n",
    "        filtered_rows = rows[mask]\n",
    "        filtered_cols = cols[mask]\n",
    "        filtered_data = data[mask]\n",
    "        \n",
    "        cooccurrence_matrix = coo_matrix((filtered_data, (filtered_rows, filtered_cols)), \n",
    "                                                  shape=cooccurrence_matrix.shape).tocsr()\n",
    "        print(f\"Number of non-zero entries after thresholding: {cooccurrence_matrix.nnz}\")\n",
    "\n",
    "    print(\"Extracting upper triangle of the co-occurrence matrix for graph creation efficiency...\")\n",
    "    cooccurrence_matrix_final = triu(cooccurrence_matrix, k=1, format='csr') \n",
    "\n",
    "    print(\"\\nMatrix construction completed!\")\n",
    "    print(f\"Original (pre-triangle extraction) co-occurrence matrix dimensions: {cooccurrence_matrix.shape}\")\n",
    "    print(f\"Final sparse matrix (upper triangular) non-zero entries: {cooccurrence_matrix_final.nnz}\")\n",
    "\n",
    "    return cooccurrence_matrix_final, recipe_to_index, unique_recipe_ids"
   ],
   "id": "c6300b62ff661",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 3. `create_network_from_cooccurrence_matrix` Function\n",
    "\n",
    "This function takes the co-occurrence matrix (created previously) and transforms it into a **network graph** using the `NetworkX` library. A graph is an intuitive representation of relationships, where nodes are recipes and edges represent their similarity (based on shared ingredients).\n",
    "\n",
    "### What it Does:\n",
    "* Takes the `cooccurrence_matrix` (which should be a sparse matrix) and an `index_to_original_id_map` (to convert numerical node indices into readable recipe IDs) as input.\n",
    "* Uses NetworkX's built-in functions (`nx.from_scipy_sparse_array` or `nx.from_numpy_array`) to quickly create a graph from the matrix data. These methods are highly optimized.\n",
    "* If the matrix type is not recognized, it falls back to a manual (slower) method for adding nodes and edges.\n",
    "* Once a graph with numerical nodes (indices) is created, it **relabel**s these nodes using the `index_to_original_id_map`, replacing indices with the original recipe IDs. This makes the graph more understandable.\n",
    "* Prints information about the process status, including execution times and graph dimensions.\n",
    "* Includes an example of printing a random edge and its weight to verify the graph structure.\n",
    "* Returns the complete and relabeled NetworkX graph."
   ],
   "id": "d16c3ed6fb034870"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:28:14.036013Z",
     "start_time": "2025-05-22T18:28:14.030780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_network_from_cooccurrence_matrix(cooccurrence_matrix, index_to_original_id_map):\n",
    "    \"\"\"\n",
    "    Transforms a weighted co-occurrence matrix into an undirected NetworkX graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Starting graph creation process...\")\n",
    "    start_total_time = time.time()\n",
    "\n",
    "    num_recipes = cooccurrence_matrix.shape[0]\n",
    "\n",
    "    print(f\"Total unique recipes identified: {num_recipes}\")\n",
    "    print(\"Attempting to create NetworkX graph from the co-occurrence matrix...\")\n",
    "\n",
    "    graph_creation_start_time = time.time()\n",
    "\n",
    "    if isinstance(cooccurrence_matrix, csr_matrix):\n",
    "        G_indexed = nx.from_scipy_sparse_array(cooccurrence_matrix, create_using=nx.Graph, edge_attribute='weight')\n",
    "    elif isinstance(cooccurrence_matrix, np.ndarray):\n",
    "        G_indexed = nx.from_numpy_array(cooccurrence_matrix, create_using=nx.Graph, edge_attribute='weight')\n",
    "    else:\n",
    "        print(\"Warning: cooccurrence_matrix is not a scipy.sparse.csr_matrix or numpy.ndarray. Falling back to manual edge addition.\")\n",
    "        G_indexed = nx.Graph()\n",
    "        for i in range(num_recipes):\n",
    "            G_indexed.add_node(i)\n",
    "\n",
    "        if hasattr(cooccurrence_matrix, 'nonzero'):\n",
    "            rows, cols = cooccurrence_matrix.nonzero()\n",
    "            for r_idx, c_idx in zip(rows, cols):\n",
    "                if r_idx < c_idx:\n",
    "                    weight = cooccurrence_matrix[r_idx, c_idx]\n",
    "                    if weight > 0:\n",
    "                        G_indexed.add_edge(r_idx, c_idx, weight=weight)\n",
    "        else:\n",
    "            for i in range(num_recipes):\n",
    "                for j in range(i + 1, num_recipes):\n",
    "                    weight = cooccurrence_matrix[i, j]\n",
    "                    if weight > 0:\n",
    "                        G_indexed.add_edge(i, j, weight=weight)\n",
    "\n",
    "    print(f\"Initial graph with integer indices created in {time.time() - graph_creation_start_time:.2f} seconds.\")\n",
    "    print(f\"Graph has {G_indexed.number_of_nodes()} nodes and {G_indexed.number_of_edges()} edges.\")\n",
    "\n",
    "    print(\"Relabeling nodes from integer indices to original recipe IDs...\")\n",
    "    relabel_start_time = time.time()\n",
    "    \n",
    "    mapping_for_relabel = {idx: index_to_original_id_map[idx] for idx in G_indexed.nodes()}\n",
    "\n",
    "    G = nx.relabel_nodes(G_indexed, mapping_for_relabel)\n",
    "    print(f\"Nodes relabeled in {time.time() - relabel_start_time:.2f} seconds.\")\n",
    "\n",
    "    print(f\"\\nGraph creation completed. Total time: {time.time() - start_total_time:.2f} seconds.\")\n",
    "    print(f\"Final graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "    print(\"Example of an edge and its weight:\")\n",
    "    if G.number_of_edges() > 0:\n",
    "        sample_edge = next(iter(G.edges(data=True)))\n",
    "        u, v, data = sample_edge\n",
    "        print(f\"Edge between recipe {u} and recipe {v} with weight {data['weight']}\")\n",
    "    else:\n",
    "        print(\"No edges found in the graph (check data or weight threshold if applied).\")\n",
    "\n",
    "    return G"
   ],
   "id": "2afd81a1cf75a853",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 3. Executing the `build_cooccurrence_matrix` Function\n",
    "\n",
    "This block is where the `build_cooccurrence_matrix` function is actually called with your desired parameters. It's the starting point of your analysis pipeline.\n",
    "\n",
    "### What it Does:\n",
    "* Defines the `file_path` to your dataset.\n",
    "* Calls `build_cooccurrence_matrix`, passing parameters for sampling (`sample_percentage=0.20`, meaning 20% of recipes) and the weight threshold (`threshold_weight=7`). The threshold of 7 means that two recipes will be considered connected only if they share **more than 7 ingredients**.\n",
    "* Saves the results returned by the function into the variables:\n",
    "    * `cooc_matrix_filtered`: The resulting co-occurrence matrix.\n",
    "    * `recipe_map_filtered`: The dictionary mapping recipe IDs to indices.\n",
    "    * `ids_filtered`: The NumPy array of sampled recipe IDs.\n",
    "* Prints the dimensions of the final matrix and the number of non-zero entries (NNZ), which represent the remaining significant connections."
   ],
   "id": "32eebf016e2adb17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:28:20.679544Z",
     "start_time": "2025-05-22T18:28:14.037149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cooc_matrix_filtered, recipe_map_filtered, ids_filtered = build_cooccurrence_matrix(file_path, sample_percentage=0.40, threshold_weight=7)\n",
    "print(f\"Filtered matrix shape: {cooc_matrix_filtered.shape}, NNZ: {cooc_matrix_filtered.nnz}\")\n",
    "\n",
    "index_to_recipe_id_map = {idx: recipe_id for recipe_id, idx in recipe_map_filtered.items()}\n",
    "\n",
    "recipe_network = create_network_from_cooccurrence_matrix(cooc_matrix_filtered, index_to_recipe_id_map)\n",
    "\n",
    "print(\"\\nStarting graph analysis:\")\n",
    "print(f\"Number of nodes: {recipe_network.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {recipe_network.number_of_edges()}\")"
   ],
   "id": "1a64129a70efc3df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./culinaryDB/04_Recipe-Ingredients_Aliases.csv...\n",
      "\n",
      "Applying sampling: Keeping 40% of unique recipes...\n",
      "Original unique recipes: 45749\n",
      "Sampled unique recipes: 18299\n",
      "DataFrame filtered to 182950 rows for sampled recipes.\n",
      "Removed 17902 duplicate (Recipe ID, Entity ID) pairs.\n",
      "Mapping recipe and ingredient IDs to indices...\n",
      "Found 18299 unique recipes and 635 unique ingredients.\n",
      "Creating the sparse bipartite matrix (Recipes x Ingredients)...\n",
      "Sparse bipartite matrix created in 0.00 seconds.\n",
      "Calculating the co-occurrence matrix via matrix multiplication (B @ B.T)...\n",
      "Co-occurrence matrix calculated in 2.26 seconds.\n",
      "Applying a weight threshold of > 7 to the co-occurrence matrix...\n",
      "Number of non-zero entries after thresholding: 453956\n",
      "Extracting upper triangle of the co-occurrence matrix for graph creation efficiency...\n",
      "\n",
      "Matrix construction completed!\n",
      "Original (pre-triangle extraction) co-occurrence matrix dimensions: (18299, 18299)\n",
      "Final sparse matrix (upper triangular) non-zero entries: 226978\n",
      "Filtered matrix shape: (18299, 18299), NNZ: 226978\n",
      "Starting graph creation process...\n",
      "Total unique recipes identified: 18299\n",
      "Attempting to create NetworkX graph from the co-occurrence matrix...\n",
      "Initial graph with integer indices created in 0.48 seconds.\n",
      "Graph has 18299 nodes and 226978 edges.\n",
      "Relabeling nodes from integer indices to original recipe IDs...\n",
      "Nodes relabeled in 0.39 seconds.\n",
      "\n",
      "Graph creation completed. Total time: 0.87 seconds.\n",
      "Final graph has 18299 nodes and 226978 edges.\n",
      "Example of an edge and its weight:\n",
      "Edge between recipe 4 and recipe 332 with weight 8\n",
      "\n",
      "Starting graph analysis:\n",
      "Number of nodes: 18299\n",
      "Number of edges: 226978\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 4. Save in `.net` file"
   ],
   "id": "2ecef07f726fc78d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:28:21.026533Z",
     "start_time": "2025-05-22T18:28:20.680942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if recipe_network.number_of_nodes() > 0: # Only save if there are nodes\n",
    "    nx.write_pajek(recipe_network, \"nets/recipe_similarity_network.net\")\n",
    "    print(\"\\nGraph saved in Pajek NET format: recipe_similarity_network.net\")\n",
    "else:\n",
    "    print(\"\\nGraph not saved: no nodes in graph to save.\")"
   ],
   "id": "27f48b7455c66240",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph saved in Pajek NET format: recipe_similarity_network.net\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 5. Basic Analysis"
   ],
   "id": "28f0e22ae5e9ae79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:28:46.390506Z",
     "start_time": "2025-05-22T18:28:21.027305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example of some basic analyses:\n",
    "# Average degree\n",
    "if recipe_network.number_of_nodes() > 0:\n",
    "    average_degree = sum(dict(recipe_network.degree()).values()) / recipe_network.number_of_nodes()\n",
    "    print(f\"Average degree: {average_degree:.2f}\")\n",
    "else:\n",
    "    print(\"Cannot calculate average degree: no nodes in graph.\")\n",
    "\n",
    "# Number of connected components\n",
    "num_connected_components = nx.number_connected_components(recipe_network)\n",
    "print(f\"Number of connected components: {num_connected_components}\")\n",
    "\n",
    "# If you want to calculate centrality (e.g., degree centrality)\n",
    "if recipe_network.number_of_nodes() > 0: # Check to avoid error on empty graph\n",
    "    degree_centrality = nx.degree_centrality(recipe_network)\n",
    "    print(\"\\nTop 5 recipes by degree centrality:\")\n",
    "    for recipe, centrality in sorted(degree_centrality.items(), key=lambda item: item[1], reverse=True)[:5]:\n",
    "        print(f\"Recipe {recipe}: {centrality:.4f}\")\n",
    "else:\n",
    "    print(\"Cannot calculate centrality: no nodes in graph.\")\n",
    "\n",
    "# If you want to calculate the clustering coefficient\n",
    "if recipe_network.number_of_nodes() > 1: # Clustering requires at least 2 nodes\n",
    "    clustering_coefficient = nx.average_clustering(recipe_network, weight='weight')\n",
    "    print(f\"Average clustering coefficient (weighted): {clustering_coefficient:.4f}\")\n",
    "else:\n",
    "    print(\"Cannot calculate clustering coefficient: not enough nodes in graph.\")"
   ],
   "id": "b759dfd0b68bed4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average degree: 24.81\n",
      "Number of connected components: 10800\n",
      "\n",
      "Top 5 recipes by degree centrality:\n",
      "Recipe 33233: 0.0837\n",
      "Recipe 27240: 0.0827\n",
      "Recipe 26693: 0.0730\n",
      "Recipe 25328: 0.0691\n",
      "Recipe 29087: 0.0670\n",
      "Average clustering coefficient (weighted): 0.0898\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:28:46.393500Z",
     "start_time": "2025-05-22T18:28:46.391252Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "32b4381f53d6e194",
   "outputs": [],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
